{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结Youtube视频\n",
    "\n",
    "最近因为学习AGI，要看很多视频，一个视频10~60分钟不等的时长，很容易诱发拖延症。\n",
    "意识到总结是AI的传统艺能，所以实现一个ChatGPT总结YouTube视频功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain youtube-transcript-api openai promptlayer tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取字幕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def get_transcript(video_id):\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['zh-Hans', 'zh', 'zh-Hans', 'en'])\n",
    "    last = transcript[-1]['start']\n",
    "    need_hour = last > 3600\n",
    "    lines = []\n",
    "\n",
    "    t = transcript\n",
    "\n",
    "    for t in transcript:\n",
    "        h = int(t['start'] // 3600)\n",
    "        m = int((t['start'] - h*3600) // 60)\n",
    "        s = int(t['start'] - h*3600 - m*60)\n",
    "        if need_hour:\n",
    "            txt = f\"[{h:02}:{m:02}:{s:02}] {t['text']}\"\n",
    "        else:\n",
    "            txt = f\"[{m:02}:{s:02}] {t['text']}\"\n",
    "        lines.append(txt)\n",
    "\n",
    "    return lines\n",
    "\n",
    "import json\n",
    "def dump_transcript(video_id):\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['zh-Hans', 'zh', 'zh-Hans', 'en'])\n",
    "    with open(f'./dataset/{video_id}.json', 'w') as f:\n",
    "        json.dump(transcript, f)\n",
    "\n",
    "dump_transcript('aywZrzNaKjs')\n",
    "lines = get_transcript('aywZrzNaKjs')\n",
    "transcript = ''.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "token_encoder = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "encoded = token_encoder.encode(transcript)\n",
    "print(len(transcript), len(encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 要求ChatGPT总结(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.chat_models import PromptLayerChatOpenAI\n",
    "\n",
    "chat = PromptLayerChatOpenAI(pl_tags=[\"note-youtube-summarize\"], temperature=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = f'''请帮我总结以下内容:\n",
    "{transcript}\n",
    "'''\n",
    "\n",
    "r = chat([HumanMessage(content=t)])\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化Prompt(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_prompt = f'''你是一个专业的视频编辑，负责总结视频的精华内容。请以一段话总结整个视频为开始，然后总结视频不同的片段。输出的格式：\n",
    "\n",
    "视频的一段话总结\n",
    "[00:00] 片段总结\n",
    "[00:22] 片段总结\n",
    "...\n",
    "\n",
    "把片段控制在20个以内，请保证所有的内容简介、清晰并且完整。\n",
    "\n",
    "以下是需要总结的视频脚本：\n",
    "{transcript}\n",
    "'''\n",
    "\n",
    "r = chat([HumanMessage(content=chunk_prompt)])\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lines[-8:])\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化Prompt(v3)\n",
    "GPT的输入和输出共用一个Token空间，现在有一个新问题，就是当字幕过多时，会导致Token超出上限或者挤压输出的空间。上面的输出到四分半的位置就戛然而止。\n",
    "解决方案就是把原文拆成多份，然后再处理，处理方法有两种：\n",
    "1. Refine - 每次把前一份的结果连同当前份的数据一同提交\n",
    "2. Map-Reduce - 所有的数据处理完成之后，最后统一处理结果数据\n",
    "\n",
    "Map Reduce的最大优势，是可以并发处理，整体时间会短一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: 2 [2016, 2079]\n",
      "[00:00] blank chain what is it why should you\n",
      "[00:03] use it and how does it work let's have a\n",
      "[00:05] look\n",
      "[00:07] Lang chain is an open source framework\n",
      "[00:09] that allows developers working with AI\n",
      "[00:11] to combine large language models like\n",
      "[00:14] gbt4 with external sources of\n",
      "[00:17] computation and data the framework is\n",
      "[00:20] currently offered as a python or a\n",
      "[00:22] JavaScript package typescript to be\n",
      "[00:24] specific in this video we're going to\n",
      "[00:26] start unpacking the python framework and\n",
      "[00:29] we're going to see why the popularity of\n",
      "[00:31] the framework is exploding right now\n",
      "[00:32] especially after the introduction of\n",
      "[00:34] gpt4 in March 2023 to understand what\n",
      "[00:38] need Lang chain fills let's have a look\n",
      "[00:40] at a practical example so by now we all\n",
      "[00:43] know that chat typically or tpt4 has an\n",
      "[00:45] impressive general knowledge we can ask\n",
      "[00:47] it about almost anything and we'll get a\n",
      "[00:50] pretty good answer\n",
      "[00:51] suppose you want to know something\n",
      "[00:53] specifically from your own data your own\n",
      "[00:56] document it could be a book a PDF file a\n",
      "[00:59] database with proprietary information\n",
      "[01:02] link chain allows you to connect a large\n",
      "[01:04] language model like dbt4 to your own\n",
      "[01:07] sources of data and we're not talking\n",
      "[01:10] about pasting a snippet of a text\n",
      "[01:13] document into the chativity prompt we're\n",
      "[01:15] talking about referencing an entire\n",
      "[01:17] database filled with your own data\n",
      "[01:19] and not only that once you get the\n",
      "[01:21] information you need you can have Lang\n",
      "[01:23] chain help you take the action you want\n",
      "[01:26] to take for instance send an email with\n",
      "[01:28] some specific information\n",
      "[01:30] and the way you do that is by taking the\n",
      "[01:32] document you want your language model to\n",
      "[01:34] reference and then you slice it up into\n",
      "[01:36] smaller chunks and you store those\n",
      "[01:38] chunks in a Victor database the chunks\n",
      "[01:41] are stored as embeddings meaning they\n",
      "[01:43] are vector representations of the text\n",
      "[01:48] this allows you to build language model\n",
      "[01:50] applications that follow a general\n",
      "[01:53] pipeline a user asks an initial question\n",
      "[01:57] this question is then sent to the\n",
      "[01:59] language model and a vector\n",
      "[02:01] representation of that question is used\n",
      "[02:04] to do a similarity search in the vector\n",
      "[02:06] database this allows us to fetch the\n",
      "[02:09] relevant chunks of information from the\n",
      "[02:11] vector database and feed that to the\n",
      "[02:13] language model as well\n",
      "[02:15] now the language model has both the\n",
      "[02:17] initial question and the relevant\n",
      "[02:19] information from the vector database and\n",
      "[02:21] is therefore capable of providing an\n",
      "[02:24] answer or take an action\n",
      "[02:26] a link chain helps build applications\n",
      "[02:28] that follow a pipeline like this and\n",
      "[02:30] these applications are both data aware\n",
      "[02:33] we can reference our own data in a\n",
      "[02:35] vector store and they are authentic they\n",
      "[02:38] can take actions and not only provide\n",
      "[02:40] answers to questions\n",
      "[02:42] and these two capabilities open up for\n",
      "[02:44] an infinite number of practical use\n",
      "[02:46] cases anything involving personal\n",
      "[02:49] assistance will be huge you can have a\n",
      "[02:51] large language model book flights\n",
      "[02:53] transfer money pay taxes now imagine the\n",
      "[02:57] implications for studying and learning\n",
      "[02:58] new things you can have a large language\n",
      "[03:00] model reference an entire syllabus and\n",
      "[03:03] help you learn the material as fast as\n",
      "[03:05] possible coding data analysis data\n",
      "[03:07] science is all going to be affected by\n",
      "[03:09] this\n",
      "[03:10] one of the applications that I'm most\n",
      "[03:11] excited about is the ability to connect\n",
      "[03:14] large language models to existing\n",
      "[03:17] company data such as customer data\n",
      "[03:19] marketing data and so on\n",
      "[03:21] I think we're going to see an\n",
      "[03:22] exponential progress in data analytics\n",
      "[03:24] and data science our ability to connect\n",
      "[03:27] the large language models to Advanced\n",
      "[03:29] apis such as metas API or Google's API\n",
      "[03:32] is really gonna gonna make things take\n",
      "[03:35] off\n",
      "[03:38] so the main value proposition of Lang\n",
      "[03:40] chain can be divided into three main\n",
      "[03:42] Concepts\n",
      "[03:44] we have the llm wrappers that allows us\n",
      "[03:46] to connect to large language models like\n",
      "[03:49] gbt4 or the ones from hugging face\n",
      "[03:52] prompt templates allows us to avoid\n",
      "[03:55] having to hard code text which is the\n",
      "[03:58] input to the llms\n",
      "[04:00] then we have indexes that allows us to\n",
      "[04:02] extract relevant information for the\n",
      "[04:04] llms the chains allows us to combine\n",
      "[04:08] multiple components together to solve a\n",
      "[04:11] specific task and build an entire llm\n",
      "[04:13] application\n",
      "[04:14] and finally we have the agents that\n",
      "[04:17] allow the llm to interact with external\n",
      "[04:19] apis\n",
      "[04:22] there's a lot to unpack in Lang chain\n",
      "[04:24] and new stuff is being added every day\n",
      "[04:26] but on a high level this is what the\n",
      "[04:28] framework looks like we have models or\n",
      "[04:30] wrappers around models we have problems\n",
      "[04:33] we have chains we have the embeddings\n",
      "[04:34] and Vector stores which are the indexes\n",
      "[04:36] and then we have the agents so what I'm\n",
      "[04:39] going to do now is I'm going to start\n",
      "[04:40] unpacking each of these elements by\n",
      "[04:42] writing code and in this video I'm going\n",
      "[04:44] to keep it high level just to get an\n",
      "[04:46] overview of the framework and a feel for\n",
      "[04:49] the different elements first thing we're\n",
      "[04:51] going to do is we're going to pip\n",
      "[04:52] install three libraries we're going to\n",
      "[04:54] need python.in to manage the environment\n",
      "[04:56] file with the passwords we're going to\n",
      "[04:58] install link chain and we're going to\n",
      "[05:00] install the Pinecone client Pinecone is\n",
      "[05:03] going to be the vector store we're going\n",
      "[05:04] to be using in this video in the\n",
      "[05:06] environment file we need the open AI API\n",
      "[05:09] key we need the pine cone environment\n",
      "[05:12] and we need the pine cone API key\n",
      "[05:15] foreign once you have signed up for a\n",
      "[05:18] Pinecone account it's free the API keys\n",
      "[05:21] and the environment name is easy to find\n",
      "[05:25] same thing is true for openai just go to\n",
      "[05:28] platform.orgmaili.com account slash API\n",
      "[05:30] keys\n",
      "[05:31] let's get started so when you have the\n",
      "[05:34] keys in an environment file all you have\n",
      "[05:36] to do is use node.n and find that in to\n",
      "[05:39] get the keys and now we're ready to go\n",
      "[05:41] so we're going to start off with the\n",
      "[05:43] llms or the wrappers around the llms\n",
      "[05:46] then I'm going to import the open AI\n",
      "[05:48] Rubber and I'm going to instantiate the\n",
      "[05:50] text DaVinci 003 completion model and\n",
      "[05:52] ask it to explain what a large language\n",
      "[05:54] model is and this is very similar to\n",
      "[05:56] when you call the open AI API directly\n",
      "[06:00] next we're going to move over to the\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, model: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "OVERLAP_LINES = 5\n",
    "def to_chunks(lines, model_name='gpt-3.5-turbo'):\n",
    "    n = '\\n'.join(lines)\n",
    "    if num_tokens_from_string(n, model_name) < 3500:\n",
    "        return [n]\n",
    "\n",
    "    l = int(len(lines)//2)\n",
    "    return to_chunks(lines[:l], model_name) + to_chunks(lines[l-OVERLAP_LINES:], model_name)\n",
    "\n",
    "chunks = to_chunks(lines)\n",
    "print(f\"Chunks: {len(chunks)}\", [num_tokens_from_string(c, 'gpt-3.5-turbo') for c in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chunk_template = '''你是一个专业的视频编辑，负责总结视频的精华内容。请以一段话总结整个视频为开始，然后总结视频不同的片段。输出的格式：\n",
    "\n",
    "视频的一段话总结\n",
    "[mm:ss] 片段总结\n",
    "[mm:ss] 片段总结\n",
    "...\n",
    "\n",
    "把片段控制在20个以内，不用重复脚本的内容，请保证所有的内容简介、清晰并且完整。\n",
    "\n",
    "以下是需要总结的视频脚本：\n",
    "{transcript}\n",
    "'''\n",
    "map_prompt = PromptTemplate(template=chunk_template, input_variables=['transcript'])\n",
    "\n",
    "summeries = [chat([HumanMessage(content=map_prompt.format(transcript=c))]) for c in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_template = \"\"\"你是一个专业的视频总编辑，负责将其它视频编辑提交的不同视频片段的总结合并成一个总结。你需要以如下的格式输出最终结果：\n",
    "\n",
    "视频的一段话总结\n",
    "[mm:ss] 片段总结\n",
    "[mm:ss] 片段总结\n",
    "\n",
    "如果其它编辑提交的内容不是中文，请翻译成中文。把片段控制在20个以内，请保证所有的内容简介、清晰并且完整。\n",
    "\n",
    "以下是需要总结的视频脚本列表：\n",
    "{transcript}\n",
    "\"\"\"\n",
    "reduce_prompt = PromptTemplate(template=summary_template, input_variables=['transcript'])\n",
    "\n",
    "txt = \"\\n===\\n\".join(s.content for s in summeries)\n",
    "res = chat([HumanMessage(content=reduce_prompt.format(transcript=txt))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频的一段话总结：本视频介绍了LangChain的核心概念，包括语言模型、聊天模型、提示模板、链、嵌入和向量存储以及代理。同时，还介绍了DaVinci 003完成模型和大型语言模型的概念。\n",
      "\n",
      "[00:07] Lang chain是一个开源框架，允许开发人员将大型语言模型与外部计算和数据源结合起来，从而构建数据感知和可执行的语言模型应用程序。\n",
      "[05:50] 介绍了DaVinci 003完成模型和大型语言模型的概念。\n",
      "[06:02] 介绍了聊天模型GBT 3.5和GBT 4以及如何使用链接链与其交互。\n",
      "[06:58] 介绍了提示模板的概念以及如何使用它们动态更改提示。\n",
      "[08:06] 介绍了链的概念以及如何将多个模型组合在一起。\n",
      "[09:01] 介绍了嵌入和向量存储的概念以及如何将文本转换为嵌入向量并将其存储在Pinecone中。\n",
      "[11:24] 介绍了代理的概念以及如何使用LangChain执行Python代码。\n"
     ]
    }
   ],
   "source": [
    "# print(reduce_prompt.format(transcript=txt))\n",
    "print(res.content)\n",
    "# print(map_prompt.format(transcript=chunks[0]), summeries[0].content)\n",
    "# print(map_prompt.format(transcript=chunks[1]), summeries[1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "测试过程中，出现了不太令人满意的结果，不过这就属于Prompt Engineering的范畴了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
