{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token研究\n",
    "\n",
    "Token是AI视角的单词，AI以Token为单位来处理数据/自然语言。\n",
    "\n",
    "确认几个问题：\n",
    "1. 中文和英文的表达会造成Token大小差异么？\n",
    "2. 一些文本格式，是否会造成Token大小差异？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中英文差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN: 24 / 36\n",
      "EN: 27 / 115\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "cn = \"Token是AI视角的单词，AI以Token为单位来处理数据/自然语言。\"\n",
    "en = \"'Token' is a term from the perspective of AI, which refers to the unit used by AI to process data/natural language.\"\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "print(f\"CN: {len(encoding.encode(cn))} / {len(cn)}\")\n",
    "print(f\"EN: {len(encoding.encode(en))} / {len(en)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，虽然长度差很多，但是Token数量基本相同，并不是中文更简短就消耗更少的Token。\n",
    "\n",
    "接下来试试更长一点的文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN: 466 / 568\n",
      "EN: 339 / 1689\n"
     ]
    }
   ],
   "source": [
    "en = \"\"\"lang chain what is it why should you use it and how does it work let's have a look\n",
    "Lang chain is an open source framework that allows developers working with AI to combine large language models like gbt4 with external sources of computation and data the framework is currently offered as a python or a JavaScript package typescript to be specific\n",
    "link chain allows you to connect a large language model like dbt4 to your own sources of data and we're not talking about pasting a snippet of a text document into the chativity prompt we're talking about referencing an entire database filled with your own data\n",
    "now the language model has both the initial question and the relevant information from the vector database and is therefore capable of providing an answer or take an action\n",
    "one of the applications that I'm most excited about is the ability to connect large language models to existing company data such as customer data marketing data and so on\n",
    "there's a lot to unpack in Lang chain and new stuff is being added every day but on a high level this is what the framework looks like we have models or wrappers around models we have problems we have chains we have the embeddings and Vector stores which are the indexes and then we have the agents\n",
    "foreign once you have signed up for a Pinecone account it's free the API keys and the environment name is easy to find same thing is true for openai just go to platform.orgmaili.com account slash API keys\n",
    "then I'm going to import the open AI Rubber and I'm going to instantiate the text DaVinci 003 completion model and ask it to explain what a large language model is and this is very similar to when you call the open AI API directly\n",
    "\"\"\"\n",
    "cn = \"\"\"LangChain是什么？为什么应该使用它？它如何工作？让我们来看看。\n",
    "LangChain是一个开源框架，允许与人工智能相关的开发人员将大型语言模型（例如gbt4）与外部的计算和数据源相结合。该框架目前以Python或JavaScript包（具体来说是TypeScript）的形式提供。\n",
    "LinkChain使您能够将像dbt4这样的大型语言模型连接到自己的数据源，我们不是在讨论将文本文档的片段粘贴到Chativity提示中，而是在讨论引用填充有自己数据的整个数据库。\n",
    "现在，语言模型既具有初始问题，又具有来自向量数据库的相关信息，因此能够提供答案或采取行动。\n",
    "我最感兴趣的应用之一是将大型语言模型连接到现有的公司数据，例如客户数据、营销数据等。\n",
    "LangChain中有很多要探讨的内容，每天都在新增新的东西，但从高层次上看，该框架由模型或模型包装器、问题、链、嵌入和向量存储器（即索引）以及代理组成。\n",
    "一旦您注册了Pinecone帐户（免费），API密钥和环境名称就很容易找到。同样适用于OpenAI，只需访问platform.orgmaili.com账户/API密钥。\n",
    "然后，我将导入OpenAI Rubber，并将实例化文本DaVinci 003完成模型，并要求它解释什么是大型语言模型，这与直接调用OpenAI API非常相似。\"\"\"\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "print(f\"CN: {len(encoding.encode(cn))} / {len(cn)}\")\n",
    "print(f\"EN: {len(encoding.encode(en))} / {len(en)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一次，英文反而比中文要少，根据我多次测试的结果，直接要求GPT翻译的中文总是比英文占用更多的Token，当然不排除优化中文表达后能降低Token的占用的可能性。\n",
    "\n",
    "所以使用什么语种并不能决定Token的多少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 格式对Token的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN: 339 / 1689\n",
      "EN With TS: 379 / 1753\n"
     ]
    }
   ],
   "source": [
    "en_with_ts = \"\"\"[00:00] lang chain what is it why should you use it and how does it work let's have a look\n",
    "[00:07] Lang chain is an open source framework that allows developers working with AI to combine large language models like gbt4 with external sources of computation and data the framework is currently offered as a python or a JavaScript package typescript to be specific\n",
    "[01:02] link chain allows you to connect a large language model like dbt4 to your own sources of data and we're not talking about pasting a snippet of a text document into the chativity prompt we're talking about referencing an entire database filled with your own data\n",
    "[02:15] now the language model has both the initial question and the relevant information from the vector database and is therefore capable of providing an answer or take an action\n",
    "[03:38] one of the applications that I'm most excited about is the ability to connect large language models to existing company data such as customer data marketing data and so on\n",
    "[04:22] there's a lot to unpack in Lang chain and new stuff is being added every day but on a high level this is what the framework looks like we have models or wrappers around models we have problems we have chains we have the embeddings and Vector stores which are the indexes and then we have the agents\n",
    "[05:15] foreign once you have signed up for a Pinecone account it's free the API keys and the environment name is easy to find same thing is true for openai just go to platform.orgmaili.com account slash API keys\n",
    "[05:46] then I'm going to import the open AI Rubber and I'm going to instantiate the text DaVinci 003 completion model and ask it to explain what a large language model is and this is very similar to when you call the open AI API directly\n",
    "\"\"\"\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "print(f\"EN: {len(encoding.encode(en))} / {len(en)}\")\n",
    "print(f\"EN With TS: {len(encoding.encode(en_with_ts))} / {len(en_with_ts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：一些格式字符会导致Token的区别，如果格式字符复杂的话，Token上升比率还会更高。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
