[{"text": "blank chain what is it why should you", "start": 0.12, "duration": 5.82}, {"text": "use it and how does it work let's have a", "start": 3.3, "duration": 4.019}, {"text": "look", "start": 5.94, "duration": 3.48}, {"text": "Lang chain is an open source framework", "start": 7.319, "duration": 4.381}, {"text": "that allows developers working with AI", "start": 9.42, "duration": 4.679}, {"text": "to combine large language models like", "start": 11.7, "duration": 5.46}, {"text": "gbt4 with external sources of", "start": 14.099, "duration": 6.481}, {"text": "computation and data the framework is", "start": 17.16, "duration": 5.4}, {"text": "currently offered as a python or a", "start": 20.58, "duration": 4.26}, {"text": "JavaScript package typescript to be", "start": 22.56, "duration": 4.379}, {"text": "specific in this video we're going to", "start": 24.84, "duration": 4.74}, {"text": "start unpacking the python framework and", "start": 26.939, "duration": 4.201}, {"text": "we're going to see why the popularity of", "start": 29.58, "duration": 2.94}, {"text": "the framework is exploding right now", "start": 31.14, "duration": 3.12}, {"text": "especially after the introduction of", "start": 32.52, "duration": 5.94}, {"text": "gpt4 in March 2023 to understand what", "start": 34.26, "duration": 6.119}, {"text": "need Lang chain fills let's have a look", "start": 38.46, "duration": 4.86}, {"text": "at a practical example so by now we all", "start": 40.379, "duration": 5.581}, {"text": "know that chat typically or tpt4 has an", "start": 43.32, "duration": 4.62}, {"text": "impressive general knowledge we can ask", "start": 45.96, "duration": 4.32}, {"text": "it about almost anything and we'll get a", "start": 47.94, "duration": 3.599}, {"text": "pretty good answer", "start": 50.28, "duration": 2.82}, {"text": "suppose you want to know something", "start": 51.539, "duration": 4.5}, {"text": "specifically from your own data your own", "start": 53.1, "duration": 6.06}, {"text": "document it could be a book a PDF file a", "start": 56.039, "duration": 6.54}, {"text": "database with proprietary information", "start": 59.16, "duration": 5.52}, {"text": "link chain allows you to connect a large", "start": 62.579, "duration": 5.101}, {"text": "language model like dbt4 to your own", "start": 64.68, "duration": 5.34}, {"text": "sources of data and we're not talking", "start": 67.68, "duration": 5.58}, {"text": "about pasting a snippet of a text", "start": 70.02, "duration": 5.82}, {"text": "document into the chativity prompt we're", "start": 73.26, "duration": 4.32}, {"text": "talking about referencing an entire", "start": 75.84, "duration": 3.959}, {"text": "database filled with your own data", "start": 77.58, "duration": 4.32}, {"text": "and not only that once you get the", "start": 79.799, "duration": 4.14}, {"text": "information you need you can have Lang", "start": 81.9, "duration": 4.38}, {"text": "chain help you take the action you want", "start": 83.939, "duration": 4.621}, {"text": "to take for instance send an email with", "start": 86.28, "duration": 3.839}, {"text": "some specific information", "start": 88.56, "duration": 3.9}, {"text": "and the way you do that is by taking the", "start": 90.119, "duration": 4.441}, {"text": "document you want your language model to", "start": 92.46, "duration": 4.26}, {"text": "reference and then you slice it up into", "start": 94.56, "duration": 3.9}, {"text": "smaller chunks and you store those", "start": 96.72, "duration": 4.56}, {"text": "chunks in a Victor database the chunks", "start": 98.46, "duration": 5.22}, {"text": "are stored as embeddings meaning they", "start": 101.28, "duration": 7.32}, {"text": "are vector representations of the text", "start": 103.68, "duration": 7.259}, {"text": "this allows you to build language model", "start": 108.6, "duration": 4.559}, {"text": "applications that follow a general", "start": 110.939, "duration": 6.061}, {"text": "pipeline a user asks an initial question", "start": 113.159, "duration": 6.6}, {"text": "this question is then sent to the", "start": 117.0, "duration": 4.799}, {"text": "language model and a vector", "start": 119.759, "duration": 4.32}, {"text": "representation of that question is used", "start": 121.799, "duration": 4.68}, {"text": "to do a similarity search in the vector", "start": 124.079, "duration": 5.04}, {"text": "database this allows us to fetch the", "start": 126.479, "duration": 5.34}, {"text": "relevant chunks of information from the", "start": 129.119, "duration": 4.861}, {"text": "vector database and feed that to the", "start": 131.819, "duration": 4.021}, {"text": "language model as well", "start": 133.98, "duration": 3.78}, {"text": "now the language model has both the", "start": 135.84, "duration": 3.6}, {"text": "initial question and the relevant", "start": 137.76, "duration": 4.08}, {"text": "information from the vector database and", "start": 139.44, "duration": 4.56}, {"text": "is therefore capable of providing an", "start": 141.84, "duration": 4.68}, {"text": "answer or take an action", "start": 144.0, "duration": 4.5}, {"text": "a link chain helps build applications", "start": 146.52, "duration": 4.38}, {"text": "that follow a pipeline like this and", "start": 148.5, "duration": 4.739}, {"text": "these applications are both data aware", "start": 150.9, "duration": 4.5}, {"text": "we can reference our own data in a", "start": 153.239, "duration": 5.281}, {"text": "vector store and they are authentic they", "start": 155.4, "duration": 5.1}, {"text": "can take actions and not only provide", "start": 158.52, "duration": 3.719}, {"text": "answers to questions", "start": 160.5, "duration": 4.019}, {"text": "and these two capabilities open up for", "start": 162.239, "duration": 4.561}, {"text": "an infinite number of practical use", "start": 164.519, "duration": 4.621}, {"text": "cases anything involving personal", "start": 166.8, "duration": 4.799}, {"text": "assistance will be huge you can have a", "start": 169.14, "duration": 4.2}, {"text": "large language model book flights", "start": 171.599, "duration": 5.521}, {"text": "transfer money pay taxes now imagine the", "start": 173.34, "duration": 5.46}, {"text": "implications for studying and learning", "start": 177.12, "duration": 3.72}, {"text": "new things you can have a large language", "start": 178.8, "duration": 4.5}, {"text": "model reference an entire syllabus and", "start": 180.84, "duration": 4.259}, {"text": "help you learn the material as fast as", "start": 183.3, "duration": 4.14}, {"text": "possible coding data analysis data", "start": 185.099, "duration": 3.901}, {"text": "science is all going to be affected by", "start": 187.44, "duration": 2.579}, {"text": "this", "start": 189.0, "duration": 2.94}, {"text": "one of the applications that I'm most", "start": 190.019, "duration": 4.5}, {"text": "excited about is the ability to connect", "start": 191.94, "duration": 5.28}, {"text": "large language models to existing", "start": 194.519, "duration": 4.621}, {"text": "company data such as customer data", "start": 197.22, "duration": 3.84}, {"text": "marketing data and so on", "start": 199.14, "duration": 3.12}, {"text": "I think we're going to see an", "start": 201.06, "duration": 3.179}, {"text": "exponential progress in data analytics", "start": 202.26, "duration": 4.74}, {"text": "and data science our ability to connect", "start": 204.239, "duration": 5.341}, {"text": "the large language models to Advanced", "start": 207.0, "duration": 5.58}, {"text": "apis such as metas API or Google's API", "start": 209.58, "duration": 5.76}, {"text": "is really gonna gonna make things take", "start": 212.58, "duration": 5.06}, {"text": "off", "start": 215.34, "duration": 2.3}, {"text": "so the main value proposition of Lang", "start": 218.58, "duration": 3.54}, {"text": "chain can be divided into three main", "start": 220.5, "duration": 4.14}, {"text": "Concepts", "start": 222.12, "duration": 4.86}, {"text": "we have the llm wrappers that allows us", "start": 224.64, "duration": 4.98}, {"text": "to connect to large language models like", "start": 226.98, "duration": 5.179}, {"text": "gbt4 or the ones from hugging face", "start": 229.62, "duration": 5.46}, {"text": "prompt templates allows us to avoid", "start": 232.159, "duration": 6.041}, {"text": "having to hard code text which is the", "start": 235.08, "duration": 5.1}, {"text": "input to the llms", "start": 238.2, "duration": 4.319}, {"text": "then we have indexes that allows us to", "start": 240.18, "duration": 4.44}, {"text": "extract relevant information for the", "start": 242.519, "duration": 5.72}, {"text": "llms the chains allows us to combine", "start": 244.62, "duration": 6.66}, {"text": "multiple components together to solve a", "start": 248.239, "duration": 5.441}, {"text": "specific task and build an entire llm", "start": 251.28, "duration": 3.599}, {"text": "application", "start": 253.68, "duration": 3.36}, {"text": "and finally we have the agents that", "start": 254.879, "duration": 5.04}, {"text": "allow the llm to interact with external", "start": 257.04, "duration": 5.22}, {"text": "apis", "start": 259.919, "duration": 4.381}, {"text": "there's a lot to unpack in Lang chain", "start": 262.26, "duration": 4.14}, {"text": "and new stuff is being added every day", "start": 264.3, "duration": 4.2}, {"text": "but on a high level this is what the", "start": 266.4, "duration": 4.56}, {"text": "framework looks like we have models or", "start": 268.5, "duration": 4.5}, {"text": "wrappers around models we have problems", "start": 270.96, "duration": 3.72}, {"text": "we have chains we have the embeddings", "start": 273.0, "duration": 3.479}, {"text": "and Vector stores which are the indexes", "start": 274.68, "duration": 4.62}, {"text": "and then we have the agents so what I'm", "start": 276.479, "duration": 4.201}, {"text": "going to do now is I'm going to start", "start": 279.3, "duration": 3.3}, {"text": "unpacking each of these elements by", "start": 280.68, "duration": 3.9}, {"text": "writing code and in this video I'm going", "start": 282.6, "duration": 4.26}, {"text": "to keep it high level just to get an", "start": 284.58, "duration": 4.559}, {"text": "overview of the framework and a feel for", "start": 286.86, "duration": 4.74}, {"text": "the different elements first thing we're", "start": 289.139, "duration": 3.721}, {"text": "going to do is we're going to pip", "start": 291.6, "duration": 3.06}, {"text": "install three libraries we're going to", "start": 292.86, "duration": 3.96}, {"text": "need python.in to manage the environment", "start": 294.66, "duration": 4.02}, {"text": "file with the passwords we're going to", "start": 296.82, "duration": 3.36}, {"text": "install link chain and we're going to", "start": 298.68, "duration": 4.44}, {"text": "install the Pinecone client Pinecone is", "start": 300.18, "duration": 4.26}, {"text": "going to be the vector store we're going", "start": 303.12, "duration": 3.84}, {"text": "to be using in this video in the", "start": 304.44, "duration": 5.22}, {"text": "environment file we need the open AI API", "start": 306.96, "duration": 5.459}, {"text": "key we need the pine cone environment", "start": 309.66, "duration": 6.0}, {"text": "and we need the pine cone API key", "start": 312.419, "duration": 6.361}, {"text": "foreign once you have signed up for a", "start": 315.66, "duration": 6.06}, {"text": "Pinecone account it's free the API keys", "start": 318.78, "duration": 6.419}, {"text": "and the environment name is easy to find", "start": 321.72, "duration": 6.319}, {"text": "same thing is true for openai just go to", "start": 325.199, "duration": 5.401}, {"text": "platform.orgmaili.com account slash API", "start": 328.039, "duration": 3.821}, {"text": "keys", "start": 330.6, "duration": 3.599}, {"text": "let's get started so when you have the", "start": 331.86, "duration": 4.98}, {"text": "keys in an environment file all you have", "start": 334.199, "duration": 5.761}, {"text": "to do is use node.n and find that in to", "start": 336.84, "duration": 5.04}, {"text": "get the keys and now we're ready to go", "start": 339.96, "duration": 3.959}, {"text": "so we're going to start off with the", "start": 341.88, "duration": 4.259}, {"text": "llms or the wrappers around the llms", "start": 343.919, "duration": 4.56}, {"text": "then I'm going to import the open AI", "start": 346.139, "duration": 4.081}, {"text": "Rubber and I'm going to instantiate the", "start": 348.479, "duration": 4.321}, {"text": "text DaVinci 003 completion model and", "start": 350.22, "duration": 4.319}, {"text": "ask it to explain what a large language", "start": 352.8, "duration": 3.899}, {"text": "model is and this is very similar to", "start": 354.539, "duration": 6.241}, {"text": "when you call the open AI API directly", "start": 356.699, "duration": 6.0}, {"text": "next we're going to move over to the", "start": 360.78, "duration": 5.639}, {"text": "chat model so gbt 3.5 and gbt4 are chat", "start": 362.699, "duration": 4.681}, {"text": "models", "start": 366.419, "duration": 3.0}, {"text": "and in order to interact with the chat", "start": 367.38, "duration": 3.96}, {"text": "model through link chain we're going to", "start": 369.419, "duration": 4.441}, {"text": "import a schema consisting of three", "start": 371.34, "duration": 5.04}, {"text": "parts an AI message a human message and", "start": 373.86, "duration": 3.899}, {"text": "a system message", "start": 376.38, "duration": 3.24}, {"text": "and then we're going to import chat open", "start": 377.759, "duration": 4.621}, {"text": "AI the system message is what you use to", "start": 379.62, "duration": 4.199}, {"text": "configure the system when you use a", "start": 382.38, "duration": 3.9}, {"text": "model and the human message is the user", "start": 383.819, "duration": 3.781}, {"text": "message", "start": 386.28, "duration": 2.58}, {"text": "thank you", "start": 387.6, "duration": 4.2}, {"text": "to use the chat model you combine the", "start": 388.86, "duration": 4.619}, {"text": "system message and the human message in", "start": 391.8, "duration": 3.72}, {"text": "a list and then you use that as an input", "start": 393.479, "duration": 5.22}, {"text": "to the chat model", "start": 395.52, "duration": 6.899}, {"text": "here I'm using GPT 3.5 turbo you could", "start": 398.699, "duration": 6.181}, {"text": "have used gpt4 I'm not using that", "start": 402.419, "duration": 4.861}, {"text": "because the open AI service is a little", "start": 404.88, "duration": 5.599}, {"text": "bit Limited at the moment", "start": 407.28, "duration": 3.199}, {"text": "so this works no problem let's move to", "start": 413.52, "duration": 4.56}, {"text": "the next concept which is prompt", "start": 415.919, "duration": 4.681}, {"text": "templates so prompts are what we are", "start": 418.08, "duration": 4.86}, {"text": "going to send to our language model but", "start": 420.6, "duration": 4.26}, {"text": "most of the time these problems are not", "start": 422.94, "duration": 3.24}, {"text": "going to be static they're going to be", "start": 424.86, "duration": 3.059}, {"text": "dynamic they're going to be used in an", "start": 426.18, "duration": 3.66}, {"text": "application and to do that link chain", "start": 427.919, "duration": 3.481}, {"text": "has something called prompt templates", "start": 429.84, "duration": 4.079}, {"text": "and what that allows us to do is to take", "start": 431.4, "duration": 5.76}, {"text": "a piece of text and inject a user input", "start": 433.919, "duration": 5.881}, {"text": "into that text and we can then format", "start": 437.16, "duration": 5.099}, {"text": "The Prompt with the user input and feed", "start": 439.8, "duration": 5.94}, {"text": "that to the language model", "start": 442.259, "duration": 5.88}, {"text": "so this is the most basic example but it", "start": 445.74, "duration": 4.5}, {"text": "allows us to dynamically change the", "start": 448.139, "duration": 5.601}, {"text": "prompt with the user input", "start": 450.24, "duration": 3.5}, {"text": "the third concept we want to Overlook at", "start": 460.5, "duration": 6.44}, {"text": "is the concept of a chain", "start": 462.9, "duration": 4.04}, {"text": "a chain takes a language model and a", "start": 467.4, "duration": 4.26}, {"text": "prompt template and combines them into", "start": 469.8, "duration": 4.14}, {"text": "an interface that takes an input from", "start": 471.66, "duration": 5.46}, {"text": "the user and outputs an answer from the", "start": 473.94, "duration": 5.94}, {"text": "language model sort of like a composite", "start": 477.12, "duration": 5.22}, {"text": "function where the inner function is the", "start": 479.88, "duration": 4.2}, {"text": "prompt template and the outer function", "start": 482.34, "duration": 3.66}, {"text": "is the language model", "start": 484.08, "duration": 4.019}, {"text": "we can also build sequential chains", "start": 486.0, "duration": 4.56}, {"text": "where we have one chain returning an", "start": 488.099, "duration": 4.621}, {"text": "output and then a second chain taking", "start": 490.56, "duration": 4.259}, {"text": "the output from the first chain as an", "start": 492.72, "duration": 3.419}, {"text": "input", "start": 494.819, "duration": 3.421}, {"text": "so here we have the first chain that", "start": 496.139, "duration": 3.661}, {"text": "takes a machine learning concept and", "start": 498.24, "duration": 3.359}, {"text": "gives us a brief explanation of that", "start": 499.8, "duration": 4.739}, {"text": "concept the second chain then takes the", "start": 501.599, "duration": 5.04}, {"text": "description of the first concept and", "start": 504.539, "duration": 4.38}, {"text": "explains it to me like I'm five years", "start": 506.639, "duration": 4.521}, {"text": "old", "start": 508.919, "duration": 2.241}, {"text": "then we simply combine the two chains", "start": 512.159, "duration": 4.56}, {"text": "the first chain called chain and then", "start": 514.2, "duration": 5.16}, {"text": "the second chain called chain two into", "start": 516.719, "duration": 4.32}, {"text": "an overall chain", "start": 519.36, "duration": 5.119}, {"text": "and run that chain", "start": 521.039, "duration": 3.44}, {"text": "and we see that the overall chain", "start": 526.92, "duration": 5.22}, {"text": "returns both the first description of", "start": 529.2, "duration": 6.0}, {"text": "the concept and the explain it to me", "start": 532.14, "duration": 7.02}, {"text": "like I'm 5 explanation of the concept", "start": 535.2, "duration": 6.18}, {"text": "all right let's move on to embeddings", "start": 539.16, "duration": 4.26}, {"text": "and Vector stores but before we do that", "start": 541.38, "duration": 4.98}, {"text": "let me just change the explainer to me", "start": 543.42, "duration": 5.4}, {"text": "like I'm five prompt so that we get a", "start": 546.36, "duration": 4.8}, {"text": "few more words", "start": 548.82, "duration": 6.44}, {"text": "I'm gonna go with 500 Words", "start": 551.16, "duration": 4.1}, {"text": "all right so this is a slightly longer", "start": 559.26, "duration": 5.72}, {"text": "explanation for a five-year-old", "start": 561.06, "duration": 3.92}, {"text": "now what I'm going to do is I'm going to", "start": 567.14, "duration": 4.0}, {"text": "check this text and I'm going to split", "start": 569.279, "duration": 3.901}, {"text": "it into chunks because we want to store", "start": 571.14, "duration": 5.4}, {"text": "it in a vector store in Pinecone", "start": 573.18, "duration": 5.7}, {"text": "and Lang chain has a text bitter tool", "start": 576.54, "duration": 3.919}, {"text": "for that so I'm going to import", "start": 578.88, "duration": 4.56}, {"text": "recursive character text splitter and", "start": 580.459, "duration": 5.621}, {"text": "then I'm going to spit the text into", "start": 583.44, "duration": 3.78}, {"text": "chunks", "start": 586.08, "duration": 3.18}, {"text": "like we talked about in the beginning of", "start": 587.22, "duration": 4.34}, {"text": "the video", "start": 589.26, "duration": 2.3}, {"text": "we can extract the plain text of the", "start": 593.22, "duration": 4.32}, {"text": "individual elements of the list with", "start": 595.86, "duration": 3.78}, {"text": "page content", "start": 597.54, "duration": 4.08}, {"text": "and what we want to do now is we want to", "start": 599.64, "duration": 5.52}, {"text": "turn this into an embedding which is", "start": 601.62, "duration": 5.46}, {"text": "just a vector representation of this", "start": 605.16, "duration": 4.5}, {"text": "text and we can use open ai's embedding", "start": 607.08, "duration": 5.819}, {"text": "model Ada", "start": 609.66, "duration": 3.239}, {"text": "with all my eyes model we can call embed", "start": 613.56, "duration": 7.32}, {"text": "query on the raw text that we just", "start": 617.7, "duration": 5.699}, {"text": "extracted from the chunks of the", "start": 620.88, "duration": 5.579}, {"text": "document and then we get the vector", "start": 623.399, "duration": 5.041}, {"text": "representation of that text or the", "start": 626.459, "duration": 3.241}, {"text": "embedding", "start": 628.44, "duration": 3.66}, {"text": "now we're going to check the chunks of", "start": 629.7, "duration": 4.079}, {"text": "the explanation document and we're going", "start": 632.1, "duration": 5.28}, {"text": "to store the vector representations in", "start": 633.779, "duration": 5.581}, {"text": "pine cone", "start": 637.38, "duration": 5.04}, {"text": "so we'll import the pine cone python", "start": 639.36, "duration": 6.0}, {"text": "client and we'll import pine cone from", "start": 642.42, "duration": 5.34}, {"text": "Lang chain Vector stores and we initiate", "start": 645.36, "duration": 5.4}, {"text": "the pine cone client with the key and", "start": 647.76, "duration": 4.5}, {"text": "the environment that we have in the", "start": 650.76, "duration": 3.78}, {"text": "environment file", "start": 652.26, "duration": 4.5}, {"text": "then we take the variable texts which", "start": 654.54, "duration": 4.62}, {"text": "consists of all the chunks of data we", "start": 656.76, "duration": 3.9}, {"text": "want to store we take the embeddings", "start": 659.16, "duration": 3.48}, {"text": "model and we take an index name and we", "start": 660.66, "duration": 4.5}, {"text": "load those chunks on the embeddings to", "start": 662.64, "duration": 4.86}, {"text": "Pine Cone and once we have the vector", "start": 665.16, "duration": 4.679}, {"text": "stored in Pinecone we can ask questions", "start": 667.5, "duration": 5.1}, {"text": "about the data stored what is magical", "start": 669.839, "duration": 5.641}, {"text": "about an auto encoder and then we can do", "start": 672.6, "duration": 5.4}, {"text": "a similarity search in Pinecone to get", "start": 675.48, "duration": 4.68}, {"text": "the answer or to extract all the", "start": 678.0, "duration": 5.06}, {"text": "relevant chunks", "start": 680.16, "duration": 2.9}, {"text": "if we head over to Pine Cone we can see", "start": 684.3, "duration": 5.88}, {"text": "that the index is here we can click on", "start": 686.94, "duration": 5.519}, {"text": "it and inspect it", "start": 690.18, "duration": 4.86}, {"text": "check the index info we have a total of", "start": 692.459, "duration": 7.581}, {"text": "13 vectors in the vector store", "start": 695.04, "duration": 5.0}, {"text": "all right so the last thing we're going", "start": 702.779, "duration": 2.641}, {"text": "to do is we're going to have a brief", "start": 704.399, "duration": 3.841}, {"text": "look at the concept of an agent", "start": 705.42, "duration": 5.76}, {"text": "now if you head over to open AI chat GPT", "start": 708.24, "duration": 5.82}, {"text": "plugins page you can see that they're", "start": 711.18, "duration": 6.96}, {"text": "showcasing a python code interpreter", "start": 714.06, "duration": 6.3}, {"text": "now we can actually do something similar", "start": 718.14, "duration": 4.379}, {"text": "in langtune", "start": 720.36, "duration": 4.2}, {"text": "so here I'm importing the create python", "start": 722.519, "duration": 4.141}, {"text": "agent as well as the python Rebel tool", "start": 724.56, "duration": 4.62}, {"text": "and the python webble from nankchain", "start": 726.66, "duration": 4.859}, {"text": "then we instantiate a python agent", "start": 729.18, "duration": 3.779}, {"text": "executor", "start": 731.519, "duration": 4.56}, {"text": "using an open AI language model", "start": 732.959, "duration": 4.681}, {"text": "and this allows us to having the", "start": 736.079, "duration": 3.781}, {"text": "language model run python code", "start": 737.64, "duration": 4.56}, {"text": "so here I want to find the roots of a", "start": 739.86, "duration": 4.62}, {"text": "quadratic function and we see that the", "start": 742.2, "duration": 5.579}, {"text": "agent executor is using numpy roots to", "start": 744.48, "duration": 5.64}, {"text": "find the roots of this quadratic", "start": 747.779, "duration": 3.18}, {"text": "function", "start": 750.12, "duration": 2.76}, {"text": "alright so this video was meant to give", "start": 750.959, "duration": 3.541}, {"text": "you a brief introduction to the Core", "start": 752.88, "duration": 4.32}, {"text": "Concepts of langchain if you want to", "start": 754.5, "duration": 4.5}, {"text": "follow along for a deep dive into the", "start": 757.2, "duration": 4.139}, {"text": "concepts hit subscribe thanks for", "start": 759.0, "duration": 4.76}, {"text": "watching", "start": 761.339, "duration": 2.421}]